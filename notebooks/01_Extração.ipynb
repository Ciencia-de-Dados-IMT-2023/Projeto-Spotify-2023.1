{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração e Transformação dos Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "API_TOKEN = str(os.getenv('API_TOKEN'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração dos dados do Million Playlist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_path: str=None, url: str=None) -> dict:\n",
    "    \"\"\"\n",
    "    Essa função lê um arquivo json de um caminho local ou de uma url\n",
    "    e retorna um dicionário com o conteúdo do arquivo.\n",
    "\n",
    "    :param file_path: caminho para o arquivo json local.\n",
    "    :param url: caminho para o arquivo json online.\n",
    "\n",
    "    :retorna: Um dicionário com o conteúdo do arquivo json.\n",
    "    \"\"\"\n",
    "\n",
    "    if url is not None:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        return data\n",
    "\n",
    "    elif file_path is not None:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            return data\n",
    "        \n",
    "\n",
    "def extract_content_from_json(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Essa função extrai o conteúdo de um arquivo json e retorna um dataframe.\n",
    "\n",
    "    :param data: Um dicionário com o conteúdo do arquivo json.\n",
    "\n",
    "    :retorna: Um dataframe com o conteúdo do arquivo json.\n",
    "    \"\"\"\n",
    "    df_musics = pd.DataFrame()\n",
    "\n",
    "    # Itera sobre as playlists\n",
    "    for playlist in data['playlists']:\n",
    "        name_playlist = playlist['name']\n",
    "        id_playlist = playlist['pid']\n",
    "\n",
    "        print(f'{id_playlist} - Playlist: {name_playlist}')\n",
    "\n",
    "        # Itera sobre as músicas da playlist\n",
    "        musics_playlist = playlist['tracks']\n",
    "\n",
    "        for music in musics_playlist:\n",
    "            # name_musica = music['track_name']\n",
    "            # id_musica = music['track_uri']\n",
    "\n",
    "            # print(f'\\tSong: {name_song} - ID: {song_id}')\n",
    "            df_musica_aux = pd.DataFrame.from_dict(music, orient='index')\n",
    "            df_musica_aux = df_musica_aux.T\n",
    "\n",
    "            # Adiciona o nome da playlist e o ID da playlist\n",
    "            df_musica_aux['playlist_name'] = name_playlist\n",
    "            df_musica_aux['playlist_id'] = id_playlist\n",
    "\n",
    "            df_musica_aux = df_musica_aux.T\n",
    "            df_musics = pd.concat([df_musics, df_musica_aux], axis=1)\n",
    "\n",
    "    return df_musics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada arquivo de playlist, extrai o conteúdo e salva em um arquivo csv\n",
    "\n",
    "files_used = [\n",
    "    'mpd.slice.0-999.json',\n",
    "    'mpd.slice.1000-1999.json',\n",
    "    'mpd.slice.2000-2999.json',\n",
    "    'mpd.slice.3000-3999.json',\n",
    "    'mpd.slice.4000-4999.json',\n",
    "    'mpd.slice.5000-5999.json',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in files_used:\n",
    "#     version = file.split('.')[2].replace('-', '_')\n",
    "\n",
    "#     data = read_json_file(file_path=f'../data/00 - Raw Data/{file}')\n",
    "#     df_musics = extract_content_from_json(data)\n",
    "#     df_musics.to_csv(f'../data/01 - Extracted Data/df_musics_{version}.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenar os dados extraídos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>album_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:0UaMYEvWZi0ZqiDOoHU3YI</td>\n",
       "      <td>spotify:artist:2wIVse2owClT7go1WT98tk</td>\n",
       "      <td>spotify:album:6vV5UrXcfyQD1wu4Qo2I9K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:6I9VzXrHxO9rA9A5euc8Ak</td>\n",
       "      <td>spotify:artist:26dSoYclwsYLMAKD3tpOr4</td>\n",
       "      <td>spotify:album:0z7pVBGOD7HCIB7S8eLkLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:0WqIKmW4BTrj3eJFmnCKMv</td>\n",
       "      <td>spotify:artist:6vWDO969PvNqNYHIOW5v0m</td>\n",
       "      <td>spotify:album:25hVFAxTlDvXbx2X2QkUkE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:1AWQoqb9bSvzTjaLralEkT</td>\n",
       "      <td>spotify:artist:31TPClRtHm23RisEBtV3X7</td>\n",
       "      <td>spotify:album:6QPkyl04rXwTGlGlcYaRoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:1lzr43nnXAijIGYnCT8M8H</td>\n",
       "      <td>spotify:artist:5EvFsr3kj42KNv97ZEnqij</td>\n",
       "      <td>spotify:album:6NmFmPX56pcLBOFMhIiKvF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_uri  \\\n",
       "0  spotify:track:0UaMYEvWZi0ZqiDOoHU3YI   \n",
       "1  spotify:track:6I9VzXrHxO9rA9A5euc8Ak   \n",
       "2  spotify:track:0WqIKmW4BTrj3eJFmnCKMv   \n",
       "3  spotify:track:1AWQoqb9bSvzTjaLralEkT   \n",
       "4  spotify:track:1lzr43nnXAijIGYnCT8M8H   \n",
       "\n",
       "                              artist_uri                             album_uri  \n",
       "0  spotify:artist:2wIVse2owClT7go1WT98tk  spotify:album:6vV5UrXcfyQD1wu4Qo2I9K  \n",
       "1  spotify:artist:26dSoYclwsYLMAKD3tpOr4  spotify:album:0z7pVBGOD7HCIB7S8eLkLI  \n",
       "2  spotify:artist:6vWDO969PvNqNYHIOW5v0m  spotify:album:25hVFAxTlDvXbx2X2QkUkE  \n",
       "3  spotify:artist:31TPClRtHm23RisEBtV3X7  spotify:album:6QPkyl04rXwTGlGlcYaRoW  \n",
       "4  spotify:artist:5EvFsr3kj42KNv97ZEnqij  spotify:album:6NmFmPX56pcLBOFMhIiKvF  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_musics_final = pd.DataFrame()\n",
    "\n",
    "for file in files_used:\n",
    "    version = file.split('.')[2].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(f'../data/01 - Extracted Data/df_musics_{version}.csv')\n",
    "\n",
    "    # Keep only the columns that we need\n",
    "    df = df[['track_uri', 'artist_uri', 'album_uri']]\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    df_musics_final = pd.concat([df_musics_final, df], axis=0)\n",
    "\n",
    "# Remove duplicates\n",
    "df_musics_final.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the final dataframe\n",
    "df_musics_final.to_csv('../data/01 - Extracted Data/df_musics_concatenate.csv', index=False)\n",
    "\n",
    "df_musics_final.head(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>album_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0UaMYEvWZi0ZqiDOoHU3YI</td>\n",
       "      <td>2wIVse2owClT7go1WT98tk</td>\n",
       "      <td>6vV5UrXcfyQD1wu4Qo2I9K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6I9VzXrHxO9rA9A5euc8Ak</td>\n",
       "      <td>26dSoYclwsYLMAKD3tpOr4</td>\n",
       "      <td>0z7pVBGOD7HCIB7S8eLkLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0WqIKmW4BTrj3eJFmnCKMv</td>\n",
       "      <td>6vWDO969PvNqNYHIOW5v0m</td>\n",
       "      <td>25hVFAxTlDvXbx2X2QkUkE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1AWQoqb9bSvzTjaLralEkT</td>\n",
       "      <td>31TPClRtHm23RisEBtV3X7</td>\n",
       "      <td>6QPkyl04rXwTGlGlcYaRoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1lzr43nnXAijIGYnCT8M8H</td>\n",
       "      <td>5EvFsr3kj42KNv97ZEnqij</td>\n",
       "      <td>6NmFmPX56pcLBOFMhIiKvF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                track_uri              artist_uri               album_uri\n",
       "0  0UaMYEvWZi0ZqiDOoHU3YI  2wIVse2owClT7go1WT98tk  6vV5UrXcfyQD1wu4Qo2I9K\n",
       "1  6I9VzXrHxO9rA9A5euc8Ak  26dSoYclwsYLMAKD3tpOr4  0z7pVBGOD7HCIB7S8eLkLI\n",
       "2  0WqIKmW4BTrj3eJFmnCKMv  6vWDO969PvNqNYHIOW5v0m  25hVFAxTlDvXbx2X2QkUkE\n",
       "3  1AWQoqb9bSvzTjaLralEkT  31TPClRtHm23RisEBtV3X7  6QPkyl04rXwTGlGlcYaRoW\n",
       "4  1lzr43nnXAijIGYnCT8M8H  5EvFsr3kj42KNv97ZEnqij  6NmFmPX56pcLBOFMhIiKvF"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_musics_final['track_uri'] = df_musics_final['track_uri'].str.replace('spotify:track:', '')\n",
    "df_musics_final['artist_uri'] = df_musics_final['artist_uri'].str.replace('spotify:artist:', '')\n",
    "df_musics_final['album_uri'] = df_musics_final['album_uri'].str.replace('spotify:album:', '')\n",
    "\n",
    "df_musics_final.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para extrair dados da API do Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_req(route: str, id: str) -> requests.models.Response:\n",
    "    url = f'https://api.spotify.com/v1/{route}/{id}'\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_TOKEN}'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f'Erro: {response.status_code}')\n",
    "        print(f'Erro: {response.json()}')\n",
    "        import sys\n",
    "        sys.exit(1)\n",
    "\n",
    "    else:\n",
    "        return response\n",
    "\n",
    "\n",
    "def get_track(id_track: str) -> pd.DataFrame:\n",
    "    data = make_req('tracks', id_track).json()\n",
    "    df = pd.DataFrame(data['tracks'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_audio_features(id_track: str) -> dict:\n",
    "    data = make_req('audio-features', id_track).json()\n",
    "    df = pd.DataFrame(data['audio_features'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_album(id_album: str) -> dict:\n",
    "    data = make_req('albums', id_album).json()\n",
    "    df = pd.DataFrame(data['albums'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_artist_data(id_artist: str) -> dict:\n",
    "    data = make_req('artists', id_artist).json()\n",
    "    df = pd.DataFrame(data['artists'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_music_features(tracks_ids: list) -> dict:\n",
    "\n",
    "    tracks_ids_str = ','.join(tracks_ids)\n",
    "    tracks_ids_str = '?ids=' + tracks_ids_str\n",
    "\n",
    "    # 1. Get track data\n",
    "    tracks_list_df = get_track(tracks_ids_str)\n",
    "\n",
    "    # Collect album ids\n",
    "    tracks_list_df['id_album'] = tracks_list_df['album'].apply(lambda x: x['id'])\n",
    "\n",
    "    # Collect artist ids\n",
    "    tracks_list_df['id_artist'] = tracks_list_df['artists'].apply(lambda x: [d['id'] for d in x])\n",
    "\n",
    "    # Expand artist ids to separate rows\n",
    "    tracks_list_df = tracks_list_df.explode('id_artist')\n",
    "\n",
    "    \n",
    "    # 2. Get audio features\n",
    "    df_audio_features = pd.DataFrame()\n",
    "    for i in range(0, len(tracks_ids), 50):\n",
    "        tracks_ids_str = ','.join(tracks_ids[i:i+50] )\n",
    "        tracks_ids_str = '?ids=' + tracks_ids_str\n",
    "        df_audio_features_aux = get_audio_features(tracks_ids_str)\n",
    "        df_audio_features = pd.concat([df_audio_features, df_audio_features_aux], axis=0)\n",
    "\n",
    "    # Filtering columns\n",
    "    df_audio_features = df_audio_features[['id', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']]\n",
    "    \n",
    "    # Merge audio features with track data\n",
    "    tracks_list_df = tracks_list_df.merge(df_audio_features, on='id', how='left')\n",
    "\n",
    "\n",
    "    # 3. Get album data\n",
    "    df_albums = pd.DataFrame()\n",
    "    albums_ids = tracks_list_df['id_album'].unique().tolist()\n",
    "    for i in range(0, len(albums_ids), 20):\n",
    "        albums_ids_str = ','.join(albums_ids[i:i+20] )\n",
    "        albums_ids_str = '?ids=' + albums_ids_str\n",
    "        df_albums_aux = get_album(albums_ids_str)\n",
    "        df_albums = pd.concat([df_albums, df_albums_aux], axis=0)\n",
    "\n",
    "    # Filtering columns\n",
    "    df_albums = df_albums[['id', 'name', 'popularity', 'release_date', 'total_tracks', 'type']]\n",
    "\n",
    "    # Rename columns\n",
    "    df_albums = df_albums.rename(columns={'id': 'id_album', 'name': 'album_name', 'popularity': 'album_popularity', 'release_date': 'album_release_date', 'total_tracks': 'album_total_tracks', 'type': 'album_type'})\n",
    "\n",
    "    # Merge album data with track data\n",
    "    tracks_list_df = tracks_list_df.merge(df_albums, on='id_album', how='left')\n",
    "    \n",
    "\n",
    "    # 4. Get artist data\n",
    "    df_artists = pd.DataFrame()\n",
    "    artists_ids = tracks_list_df['id_artist'].unique().tolist()\n",
    "    for i in range(0, len(artists_ids), 50):\n",
    "        artists_ids_str = ','.join(artists_ids[i:i+50] )\n",
    "        artists_ids_str = '?ids=' + artists_ids_str\n",
    "        df_artists_aux = get_artist_data(artists_ids_str)\n",
    "        df_artists = pd.concat([df_artists, df_artists_aux], axis=0)\n",
    "\n",
    "    # Filtering columns\n",
    "    df_artists = df_artists[['id', 'name', 'genres', 'popularity', 'type', 'followers']]\n",
    "\n",
    "    # Rename columns\n",
    "    df_artists = df_artists.rename(columns={'id': 'id_artist', 'name': 'artist_name', 'genres': 'artist_genres', 'popularity': 'artist_popularity', 'type': 'artist_type', 'followers': 'artist_followers'})\n",
    "\n",
    "    # Merge artist data with track data\n",
    "    tracks_list_df = tracks_list_df.merge(df_artists, on='id_artist', how='left')\n",
    "\n",
    "    # Collect number os followers\n",
    "    tracks_list_df['artist_followers'] = tracks_list_df['artist_followers'].apply(lambda x: x['total'])\n",
    "\n",
    "    # Expand artist ids to separate rows\n",
    "    tracks_list_df = tracks_list_df.explode('artist_genres')\n",
    "\n",
    "    # Keep only relevant artist_genres\n",
    "    relevant_artist_genres = ['pop', 'hip hop', 'r&b', 'rap', 'reggae', 'rock', 'punk', 'alternative']\n",
    "    tracks_list_df = tracks_list_df[tracks_list_df['artist_genres'].isin(relevant_artist_genres)]\n",
    "\n",
    "    tracks_list_df = tracks_list_df[[\n",
    "        'id', 'id_album', 'id_artist', 'name', 'explicit', 'duration_ms', 'popularity', # Track data\n",
    "        'acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence', # Audio features\n",
    "        'album_name', 'album_popularity', 'album_release_date', 'album_total_tracks', 'album_type', # Album data\n",
    "        'artist_name', 'artist_genres', 'artist_popularity', 'artist_type', 'artist_followers' # Artist data\n",
    "        ]]\n",
    "\n",
    "    return tracks_list_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108181"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada música (linha do df_music_final), pegar as features\n",
    "\n",
    "tracks_ids = df_musics_final['track_uri'].unique().tolist()\n",
    "len(tracks_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 54090 músicas para serem processadas\n",
      "Processando músicas 0 a 50\n",
      "Processando músicas 50 a 100\n",
      "Processando músicas 100 a 150\n",
      "Processando músicas 150 a 200\n",
      "Processando músicas 200 a 250\n",
      "Processando músicas 250 a 300\n",
      "Processando músicas 300 a 350\n",
      "Processando músicas 350 a 400\n",
      "Processando músicas 400 a 450\n",
      "Processando músicas 450 a 500\n",
      "Processando músicas 500 a 550\n",
      "Processando músicas 550 a 600\n",
      "Processando músicas 600 a 650\n",
      "Processando músicas 650 a 700\n",
      "Processando músicas 700 a 750\n",
      "Processando músicas 750 a 800\n",
      "Processando músicas 800 a 850\n",
      "Processando músicas 850 a 900\n",
      "Processando músicas 900 a 950\n",
      "Processando músicas 950 a 1000\n",
      "Processando músicas 1000 a 1050\n",
      "Processando músicas 1050 a 1100\n",
      "Processando músicas 1100 a 1150\n",
      "Processando músicas 1150 a 1200\n",
      "Processando músicas 1200 a 1250\n",
      "Processando músicas 1250 a 1300\n",
      "Processando músicas 1300 a 1350\n",
      "Processando músicas 1350 a 1400\n",
      "Processando músicas 1400 a 1450\n",
      "Processando músicas 1450 a 1500\n",
      "Processando músicas 1500 a 1550\n",
      "Processando músicas 1550 a 1600\n",
      "Processando músicas 1600 a 1650\n",
      "Processando músicas 1650 a 1700\n",
      "Processando músicas 1700 a 1750\n",
      "Processando músicas 1750 a 1800\n",
      "Processando músicas 1800 a 1850\n",
      "Processando músicas 1850 a 1900\n",
      "Processando músicas 1900 a 1950\n",
      "Processando músicas 1950 a 2000\n",
      "Processando músicas 2000 a 2050\n",
      "Processando músicas 2050 a 2100\n",
      "Processando músicas 2100 a 2150\n",
      "Processando músicas 2150 a 2200\n",
      "Processando músicas 2200 a 2250\n",
      "Processando músicas 2250 a 2300\n",
      "Processando músicas 2300 a 2350\n",
      "Processando músicas 2350 a 2400\n",
      "Processando músicas 2400 a 2450\n",
      "Processando músicas 2450 a 2500\n",
      "Processando músicas 2500 a 2550\n",
      "Processando músicas 2550 a 2600\n",
      "Processando músicas 2600 a 2650\n",
      "Processando músicas 2650 a 2700\n",
      "Processando músicas 2700 a 2750\n",
      "Processando músicas 2750 a 2800\n",
      "Processando músicas 2800 a 2850\n",
      "Processando músicas 2850 a 2900\n",
      "Processando músicas 2900 a 2950\n",
      "Processando músicas 2950 a 3000\n",
      "Processando músicas 3000 a 3050\n",
      "Processando músicas 3050 a 3100\n",
      "Processando músicas 3100 a 3150\n",
      "Processando músicas 3150 a 3200\n",
      "Processando músicas 3200 a 3250\n",
      "Processando músicas 3250 a 3300\n",
      "Processando músicas 3300 a 3350\n",
      "Processando músicas 3350 a 3400\n",
      "Processando músicas 3400 a 3450\n",
      "Processando músicas 3450 a 3500\n",
      "Processando músicas 3500 a 3550\n",
      "Processando músicas 3550 a 3600\n",
      "Processando músicas 3600 a 3650\n",
      "Processando músicas 3650 a 3700\n",
      "Processando músicas 3700 a 3750\n",
      "Processando músicas 3750 a 3800\n",
      "Processando músicas 3800 a 3850\n",
      "Processando músicas 3850 a 3900\n",
      "Processando músicas 3900 a 3950\n",
      "Processando músicas 3950 a 4000\n",
      "Processando músicas 4000 a 4050\n",
      "Processando músicas 4050 a 4100\n",
      "Processando músicas 4100 a 4150\n",
      "Processando músicas 4150 a 4200\n",
      "Processando músicas 4200 a 4250\n",
      "Processando músicas 4250 a 4300\n",
      "Processando músicas 4300 a 4350\n",
      "Processando músicas 4350 a 4400\n",
      "Processando músicas 4400 a 4450\n",
      "Processando músicas 4450 a 4500\n",
      "Processando músicas 4500 a 4550\n",
      "Processando músicas 4550 a 4600\n",
      "Processando músicas 4600 a 4650\n",
      "Processando músicas 4650 a 4700\n",
      "Processando músicas 4700 a 4750\n",
      "Processando músicas 4750 a 4800\n",
      "Processando músicas 4800 a 4850\n",
      "Processando músicas 4850 a 4900\n",
      "Processando músicas 4900 a 4950\n",
      "Processando músicas 4950 a 5000\n",
      "Processando músicas 5000 a 5050\n",
      "Processando músicas 5050 a 5100\n",
      "Processando músicas 5100 a 5150\n",
      "Processando músicas 5150 a 5200\n",
      "Processando músicas 5200 a 5250\n",
      "Processando músicas 5250 a 5300\n",
      "Processando músicas 5300 a 5350\n",
      "Processando músicas 5350 a 5400\n",
      "Processando músicas 5400 a 5450\n",
      "Processando músicas 5450 a 5500\n",
      "Processando músicas 5500 a 5550\n",
      "Processando músicas 5550 a 5600\n",
      "Processando músicas 5600 a 5650\n",
      "Processando músicas 5650 a 5700\n",
      "Processando músicas 5700 a 5750\n",
      "Processando músicas 5750 a 5800\n",
      "Processando músicas 5800 a 5850\n",
      "Processando músicas 5850 a 5900\n",
      "Processando músicas 5900 a 5950\n",
      "Processando músicas 5950 a 6000\n",
      "Processando músicas 6000 a 6050\n",
      "Processando músicas 6050 a 6100\n",
      "Processando músicas 6100 a 6150\n",
      "Processando músicas 6150 a 6200\n",
      "Processando músicas 6200 a 6250\n",
      "Processando músicas 6250 a 6300\n",
      "Processando músicas 6300 a 6350\n",
      "Processando músicas 6350 a 6400\n",
      "Processando músicas 6400 a 6450\n",
      "Processando músicas 6450 a 6500\n",
      "Processando músicas 6500 a 6550\n",
      "Processando músicas 6550 a 6600\n",
      "Processando músicas 6600 a 6650\n",
      "Processando músicas 6650 a 6700\n",
      "Processando músicas 6700 a 6750\n",
      "Processando músicas 6750 a 6800\n",
      "Processando músicas 6800 a 6850\n",
      "Processando músicas 6850 a 6900\n",
      "Processando músicas 6900 a 6950\n",
      "Processando músicas 6950 a 7000\n",
      "Processando músicas 7000 a 7050\n",
      "Processando músicas 7050 a 7100\n",
      "Processando músicas 7100 a 7150\n",
      "Processando músicas 7150 a 7200\n",
      "Processando músicas 7200 a 7250\n",
      "Processando músicas 7250 a 7300\n",
      "Processando músicas 7300 a 7350\n",
      "Processando músicas 7350 a 7400\n",
      "Processando músicas 7400 a 7450\n",
      "Processando músicas 7450 a 7500\n",
      "Processando músicas 7500 a 7550\n",
      "Processando músicas 7550 a 7600\n",
      "Processando músicas 7600 a 7650\n",
      "Processando músicas 7650 a 7700\n",
      "Processando músicas 7700 a 7750\n",
      "Processando músicas 7750 a 7800\n",
      "Processando músicas 7800 a 7850\n",
      "Processando músicas 7850 a 7900\n",
      "Processando músicas 7900 a 7950\n",
      "Processando músicas 7950 a 8000\n",
      "Processando músicas 8000 a 8050\n",
      "Processando músicas 8050 a 8100\n",
      "Processando músicas 8100 a 8150\n",
      "Processando músicas 8150 a 8200\n",
      "Processando músicas 8200 a 8250\n",
      "Processando músicas 8250 a 8300\n",
      "Processando músicas 8300 a 8350\n",
      "Processando músicas 8350 a 8400\n",
      "Processando músicas 8400 a 8450\n",
      "Processando músicas 8450 a 8500\n",
      "Processando músicas 8500 a 8550\n",
      "Processando músicas 8550 a 8600\n",
      "Processando músicas 8600 a 8650\n",
      "Processando músicas 8650 a 8700\n",
      "Processando músicas 8700 a 8750\n",
      "Processando músicas 8750 a 8800\n",
      "Processando músicas 8800 a 8850\n",
      "Processando músicas 8850 a 8900\n",
      "Processando músicas 8900 a 8950\n",
      "Processando músicas 8950 a 9000\n",
      "Processando músicas 9000 a 9050\n"
     ]
    }
   ],
   "source": [
    "# Parte 1\n",
    "\n",
    "tracks_ids_part1 = tracks_ids[:len(tracks_ids)//2]\n",
    "\n",
    "df_musics_features_final = pd.DataFrame()\n",
    "print(f'Existem {len(tracks_ids_part1)} músicas para serem processadas')\n",
    "\n",
    "for i in range(0, len(tracks_ids_part1), 50):\n",
    "    print(f'Processando músicas {i} a {i+50}')\n",
    "    try:\n",
    "        df_aux = get_music_features(tracks_ids_part1[i:i+50])\n",
    "        df_musics_features_final = pd.concat([df_musics_features_final, df_aux], axis=0)\n",
    "    except:\n",
    "        print(f'Erro processando músicas {i} a {i+50}', file=open('../data/01 - Extracted Data/df_musics_features_1_error_log.txt', 'a'))\n",
    "        continue\n",
    "\n",
    "df_musics_features_final.to_csv('../data/01 - Extracted Data/df_musics_features_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2\n",
    "\n",
    "tracks_ids_part2 = tracks_ids[len(tracks_ids)//2:]\n",
    "\n",
    "df_musics_features_final = pd.DataFrame()\n",
    "print(f'Existem {len(tracks_ids_part2)} músicas para serem processadas')\n",
    "\n",
    "for i in range(0, len(tracks_ids_part2), 50):\n",
    "    print(f'Processando músicas {i} a {i+50}')\n",
    "    try:\n",
    "        df_aux = get_music_features(tracks_ids_part2[i:i+50])\n",
    "        df_musics_features_final = pd.concat([df_musics_features_final, df_aux], axis=0)\n",
    "    except:\n",
    "        print(f'Erro processando músicas {i} a {i+50}', file=open('../data/01 - Extracted Data/df_musics_features_2_error_log.txt', 'a'))\n",
    "        continue\n",
    "\n",
    "df_musics_features_final.to_csv('../data/01 - Extracted Data/df_musics_features_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando resultados\n",
    "\n",
    "df_musics_features_1 = pd.read_csv('../data/01 - Extracted Data/df_musics_features_1.csv')\n",
    "df_musics_features_2 = pd.read_csv('../data/01 - Extracted Data/df_musics_features_2.csv')\n",
    "\n",
    "df_musics_final = pd.concat([df_musics_features_1, df_musics_features_2], axis=0)\n",
    "df_musics_final.to_csv('../data/01 - Extracted Data/df_musics_features_final.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após os dados serem extraídos e a base final ser gerada, foi necessário fazer o upload da base para o Google Drive, para que fosse possível realizar a análise exploratória e a modelagem dos dados sem depender do hardware local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que salva um csv no google drive\n",
    "\n",
    "def save_csv_to_google_drive(dataframe): \n",
    "    # Authenticate and create the PyDrive client.\n",
    "    # This only needs to be done once per notebook.\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "    file_name = 'df_musics_features_final.csv'\n",
    "    file_path = '../data/01 - Extracted Data/df_musics_features_final.csv'\n",
    "    dataframe.to_csv(file_path, index=False)\n",
    "\n",
    "    # Create & upload a file.\n",
    "    uploaded = drive.CreateFile({'title': file_name})\n",
    "    uploaded.SetContentFile(file_path)\n",
    "    uploaded.Upload()\n",
    "    print('Uploaded file with ID {}'.format(uploaded.get('id')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
