{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração e Transformação dos Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "API_TOKEN = str(os.getenv('API_TOKEN'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração dos dados do Million Playlist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_path: str=None, url: str=None) -> dict:\n",
    "    \"\"\"\n",
    "    Essa função lê um arquivo json de um caminho local ou de uma url\n",
    "    e retorna um dicionário com o conteúdo do arquivo.\n",
    "\n",
    "    :param file_path: caminho para o arquivo json local.\n",
    "    :param url: caminho para o arquivo json online.\n",
    "\n",
    "    :retorna: Um dicionário com o conteúdo do arquivo json.\n",
    "    \"\"\"\n",
    "\n",
    "    if url is not None:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        return data\n",
    "\n",
    "    elif file_path is not None:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            return data\n",
    "        \n",
    "\n",
    "def extract_content_from_json(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Essa função extrai o conteúdo de um arquivo json e retorna um dataframe.\n",
    "\n",
    "    :param data: Um dicionário com o conteúdo do arquivo json.\n",
    "\n",
    "    :retorna: Um dataframe com o conteúdo do arquivo json.\n",
    "    \"\"\"\n",
    "    df_musics = pd.DataFrame()\n",
    "\n",
    "    # Itera sobre as playlists\n",
    "    for playlist in data['playlists']:\n",
    "        name_playlist = playlist['name']\n",
    "        id_playlist = playlist['pid']\n",
    "\n",
    "        print(f'{id_playlist} - Playlist: {name_playlist}')\n",
    "\n",
    "        # Itera sobre as músicas da playlist\n",
    "        musics_playlist = playlist['tracks']\n",
    "\n",
    "        for music in musics_playlist:\n",
    "            # name_musica = music['track_name']\n",
    "            # id_musica = music['track_uri']\n",
    "\n",
    "            # print(f'\\tSong: {name_song} - ID: {song_id}')\n",
    "            df_musica_aux = pd.DataFrame.from_dict(music, orient='index')\n",
    "            df_musica_aux = df_musica_aux.T\n",
    "\n",
    "            # Adiciona o nome da playlist e o ID da playlist\n",
    "            df_musica_aux['playlist_name'] = name_playlist\n",
    "            df_musica_aux['playlist_id'] = id_playlist\n",
    "\n",
    "            df_musica_aux = df_musica_aux.T\n",
    "            df_musics = pd.concat([df_musics, df_musica_aux], axis=1)\n",
    "\n",
    "    return df_musics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada arquivo de playlist, extrai o conteúdo e salva em um arquivo csv\n",
    "\n",
    "files_used = [\n",
    "    'mpd.slice.0-999.json',\n",
    "    'mpd.slice.1000-1999.json',\n",
    "    'mpd.slice.2000-2999.json',\n",
    "    'mpd.slice.3000-3999.json',\n",
    "    'mpd.slice.4000-4999.json',\n",
    "    'mpd.slice.5000-5999.json',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in files_used:\n",
    "#     version = file.split('.')[2].replace('-', '_')\n",
    "\n",
    "#     data = read_json_file(file_path=f'../data/00 - Raw Data/{file}')\n",
    "#     df_musics = extract_content_from_json(data)\n",
    "#     df_musics.to_csv(f'../data/01 - Extracted Data/df_musics_{version}.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenar os dados extraídos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_musics_final = pd.DataFrame()\n",
    "\n",
    "for file in files_used:\n",
    "    version = file.split('.')[2].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(f'../data/01 - Extracted Data/df_musics_{version}.csv')\n",
    "\n",
    "    # Keep only the columns that we need\n",
    "    df = df[['track_uri', 'artist_uri', 'album_uri']]\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    df_musics_final = pd.concat([df_musics_final, df], axis=0)\n",
    "\n",
    "# Remove duplicates\n",
    "df_musics_final.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the final dataframe\n",
    "df_musics_final.to_csv('../data/01 - Extracted Data/df_musics_concatenate.csv', index=False)\n",
    "\n",
    "df_musics_final.head(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_musics_final['track_uri'] = df_musics_final['track_uri'].str.replace('spotify:track:', '')\n",
    "df_musics_final['artist_uri'] = df_musics_final['artist_uri'].str.replace('spotify:artist:', '')\n",
    "df_musics_final['album_uri'] = df_musics_final['album_uri'].str.replace('spotify:album:', '')\n",
    "\n",
    "df_musics_final.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para extrair dados da API do Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_req(route: str, id: str) -> requests.models.Response:\n",
    "    url = f'https://api.spotify.com/v1/{route}/{id}'\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_TOKEN}'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f'Erro: {response.status_code}')\n",
    "        print(f'Erro: {response.text}')\n",
    "\n",
    "    else:\n",
    "        return response\n",
    "\n",
    "\n",
    "def get_track(id_track: str) -> pd.DataFrame:\n",
    "    data = make_req('tracks', id_track).json()\n",
    "    df = pd.DataFrame(data['tracks'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_audio_features(id_track: str) -> dict:\n",
    "    data = make_req('audio-features', id_track).json()\n",
    "    df = pd.DataFrame(data['audio_features'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_album(id_album: str) -> dict:\n",
    "    data = make_req('albums', id_album).json()\n",
    "    df = pd.DataFrame(data['albums'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_artist_data(id_artist: str) -> dict:\n",
    "    data = make_req('artists', id_artist).json()\n",
    "    df = pd.DataFrame(data['artists'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_music_features(tracks_ids: list) -> dict:\n",
    "\n",
    "    tracks_ids_str = ','.join(tracks_ids)\n",
    "    tracks_ids_str = '?ids=' + tracks_ids_str\n",
    "\n",
    "    # 1. Get track data\n",
    "    tracks_list_df = get_track(tracks_ids_str)\n",
    "\n",
    "    # Collect album ids\n",
    "    tracks_list_df['id_album'] = tracks_list_df['album'].apply(lambda x: x['id'])\n",
    "\n",
    "    # Collect artist ids\n",
    "    tracks_list_df['id_artist'] = tracks_list_df['artists'].apply(lambda x: [d['id'] for d in x])\n",
    "\n",
    "    # Expand artist ids to separate rows\n",
    "    tracks_list_df = tracks_list_df.explode('id_artist')\n",
    "\n",
    "    \n",
    "    # 2. Get audio features\n",
    "    df_audio_features = pd.DataFrame()\n",
    "    for i in range(0, len(tracks_ids), 50):\n",
    "        tracks_ids_str = ','.join(tracks_ids[i:i+50] )\n",
    "        tracks_ids_str = '?ids=' + tracks_ids_str\n",
    "        df_audio_features_aux = get_audio_features(tracks_ids_str)\n",
    "        df_audio_features = pd.concat([df_audio_features, df_audio_features_aux], axis=0)\n",
    "\n",
    "    # Filtering columns\n",
    "    df_audio_features = df_audio_features[['id', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']]\n",
    "    \n",
    "    # Merge audio features with track data\n",
    "    tracks_list_df = tracks_list_df.merge(df_audio_features, on='id', how='left')\n",
    "\n",
    "\n",
    "    # 3. Get album data\n",
    "    df_albums = pd.DataFrame()\n",
    "    albums_ids = tracks_list_df['id_album'].unique().tolist()\n",
    "    for i in range(0, len(albums_ids), 20):\n",
    "        albums_ids_str = ','.join(albums_ids[i:i+20] )\n",
    "        albums_ids_str = '?ids=' + albums_ids_str\n",
    "        df_albums_aux = get_album(albums_ids_str)\n",
    "        df_albums = pd.concat([df_albums, df_albums_aux], axis=0)\n",
    "\n",
    "    # Filtering columns\n",
    "    df_albums = df_albums[['id', 'name', 'popularity', 'release_date', 'total_tracks', 'type']]\n",
    "\n",
    "    # Rename columns\n",
    "    df_albums = df_albums.rename(columns={'id': 'id_album', 'name': 'album_name', 'popularity': 'album_popularity', 'release_date': 'album_release_date', 'total_tracks': 'album_total_tracks', 'type': 'album_type'})\n",
    "\n",
    "    # Merge album data with track data\n",
    "    tracks_list_df = tracks_list_df.merge(df_albums, on='id_album', how='left')\n",
    "    \n",
    "\n",
    "    # 4. Get artist data\n",
    "    df_artists = pd.DataFrame()\n",
    "    artists_ids = tracks_list_df['id_artist'].unique().tolist()\n",
    "    for i in range(0, len(artists_ids), 50):\n",
    "        artists_ids_str = ','.join(artists_ids[i:i+50] )\n",
    "        artists_ids_str = '?ids=' + artists_ids_str\n",
    "        df_artists_aux = get_artist_data(artists_ids_str)\n",
    "        df_artists = pd.concat([df_artists, df_artists_aux], axis=0)\n",
    "\n",
    "    # Filtering columns\n",
    "    df_artists = df_artists[['id', 'name', 'genres', 'popularity', 'type', 'followers']]\n",
    "\n",
    "    # Rename columns\n",
    "    df_artists = df_artists.rename(columns={'id': 'id_artist', 'name': 'artist_name', 'genres': 'artist_genres', 'popularity': 'artist_popularity', 'type': 'artist_type', 'followers': 'artist_followers'})\n",
    "\n",
    "    # Merge artist data with track data\n",
    "    tracks_list_df = tracks_list_df.merge(df_artists, on='id_artist', how='left')\n",
    "\n",
    "    # Collect number os followers\n",
    "    tracks_list_df['artist_followers'] = tracks_list_df['artist_followers'].apply(lambda x: x['total'])\n",
    "\n",
    "    # Expand artist ids to separate rows\n",
    "    tracks_list_df = tracks_list_df.explode('artist_genres')\n",
    "\n",
    "    # Keep only relevant artist_genres\n",
    "    relevant_artist_genres = ['pop', 'hip hop', 'r&b', 'rap', 'reggae', 'rock', 'punk', 'alternative']\n",
    "    tracks_list_df = tracks_list_df[tracks_list_df['artist_genres'].isin(relevant_artist_genres)]\n",
    "\n",
    "    tracks_list_df = tracks_list_df[[\n",
    "        'id', 'id_album', 'id_artist', 'name', 'explicit', 'duration_ms', 'popularity', # Track data\n",
    "        'acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence', # Audio features\n",
    "        'album_name', 'album_popularity', 'album_release_date', 'album_total_tracks', 'album_type', # Album data\n",
    "        'artist_name', 'artist_genres', 'artist_popularity', 'artist_type', 'artist_followers' # Artist data\n",
    "        ]]\n",
    "\n",
    "    return tracks_list_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada música (linha do df_music_final), pegar as features\n",
    "\n",
    "tracks_ids = df_musics_final['track_uri'].unique().tolist()\n",
    "len(tracks_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parte 1\n",
    "\n",
    "# tracks_ids_part1 = tracks_ids[:len(tracks_ids)//2]\n",
    "\n",
    "# df_musics_features_final = pd.DataFrame()\n",
    "# print(f'Existem {len(tracks_ids_part1)} músicas para serem processadas')\n",
    "\n",
    "# for i in range(0, len(tracks_ids_part1), 50):\n",
    "#     print(f'Processando músicas {i} a {i+50}')\n",
    "#     try:\n",
    "#         df_aux = get_music_features(tracks_ids_part1[i:i+50])\n",
    "#         df_musics_features_final = pd.concat([df_musics_features_final, df_aux], axis=0)\n",
    "#     except:\n",
    "#         print(f'Erro processando músicas {i} a {i+50}', file=open('../data/01 - Extracted Data/df_musics_features_1_error_log.txt', 'a'))\n",
    "#         continue\n",
    "\n",
    "# df_musics_features_final.to_csv('../data/01 - Extracted Data/df_musics_features_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2\n",
    "\n",
    "tracks_ids_part2 = tracks_ids[len(tracks_ids)//2:]\n",
    "\n",
    "df_musics_features_final = pd.DataFrame()\n",
    "print(f'Existem {len(tracks_ids_part2)} músicas para serem processadas')\n",
    "\n",
    "for i in range(0, len(tracks_ids_part2), 50):\n",
    "    print(f'Processando músicas {i} a {i+50}')\n",
    "    try:\n",
    "        df_aux = get_music_features(tracks_ids_part2[i:i+50])\n",
    "        df_musics_features_final = pd.concat([df_musics_features_final, df_aux], axis=0)\n",
    "    except Exception as e:\n",
    "        print(f'Erro processando músicas {i} a {i+50}')\n",
    "        print(e, file=open('../data/01 - Extracted Data/df_musics_features_2_error_log.txt', 'a'))\n",
    "        continue\n",
    "\n",
    "df_musics_features_final.to_csv('../data/01 - Extracted Data/df_musics_features_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando resultados\n",
    "\n",
    "df_musics_features_1 = pd.read_csv('../data/01 - Extracted Data/df_musics_features_1.csv')\n",
    "df_musics_features_2 = pd.read_csv('../data/01 - Extracted Data/df_musics_features_2.csv')\n",
    "\n",
    "df_musics_final = pd.concat([df_musics_features_1, df_musics_features_2], axis=0)\n",
    "df_musics_final.to_csv('../data/01 - Extracted Data/df_musics_features_final.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após os dados serem extraídos e a base final ser gerada, foi necessário fazer o upload da base para o Google Drive, para que fosse possível realizar a análise exploratória e a modelagem dos dados sem depender do hardware local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Função que salva um csv no google drive\n",
    "\n",
    "# def save_csv_to_google_drive(dataframe): \n",
    "#     # Authenticate and create the PyDrive client.\n",
    "#     # This only needs to be done once per notebook.\n",
    "#     auth.authenticate_user()\n",
    "#     gauth = GoogleAuth()\n",
    "#     gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#     drive = GoogleDrive(gauth)\n",
    "\n",
    "#     file_name = 'df_musics_features_final.csv'\n",
    "#     file_path = '../data/01 - Extracted Data/df_musics_features_final.csv'\n",
    "#     dataframe.to_csv(file_path, index=False)\n",
    "\n",
    "#     # Create & upload a file.\n",
    "#     uploaded = drive.CreateFile({'title': file_name})\n",
    "#     uploaded.SetContentFile(file_path)\n",
    "#     uploaded.Upload()\n",
    "#     print('Uploaded file with ID {}'.format(uploaded.get('id')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
